<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reinforcement Learning Navigation</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #fff;
        }

        /* Header */
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 80px 20px;
            text-align: center;
        }

        h1 {
            font-size: 2.5rem;
            font-weight: 300;
            margin-bottom: 10px;
        }

        .subtitle {
            font-size: 1.2rem;
            opacity: 0.9;
        }

        /* Container */
        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 60px 20px;
        }

        /* Sections */
        section {
            margin-bottom: 60px;
        }

        h2 {
            font-size: 2rem;
            font-weight: 300;
            margin-bottom: 30px;
            color: #667eea;
        }

        p {
            font-size: 1.05rem;
            line-height: 1.7;
            margin-bottom: 20px;
            color: #555;
        }

        /* Video Container */
        .video-container {
            position: relative;
            padding-bottom: 56.25%;
            height: 0;
            overflow: hidden;
            margin: 40px 0;
            border-radius: 12px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.1);
        }

        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border-radius: 12px;
        }

        /* Features Grid */
        .features {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 30px;
            margin: 40px 0;
        }

        .feature {
            padding: 30px;
            background: #f8f9fa;
            border-radius: 10px;
            transition: transform 0.3s ease;
        }

        .feature:hover {
            transform: translateY(-5px);
        }

        .feature h3 {
            font-size: 1.3rem;
            margin-bottom: 15px;
            color: #667eea;
        }

        .feature p {
            font-size: 0.95rem;
            color: #666;
        }

        /* Stats */
        .stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 30px;
            margin: 40px 0;
            text-align: center;
        }

        .stat {
            padding: 20px;
        }

        .stat-value {
            font-size: 3rem;
            font-weight: 300;
            color: #667eea;
            margin-bottom: 10px;
        }

        .stat-label {
            font-size: 1rem;
            color: #666;
        }

        /* Tech Stack */
        .tech-list {
            list-style: none;
            padding: 0;
        }

        .tech-list li {
            padding: 15px 0;
            border-bottom: 1px solid #eee;
            font-size: 1rem;
        }

        .tech-list li:last-child {
            border-bottom: none;
        }

        .tech-list strong {
            color: #667eea;
            margin-right: 10px;
        }

        /* Footer */
        footer {
            background: #f8f9fa;
            padding: 40px 20px;
            text-align: center;
            margin-top: 60px;
        }

        footer a {
            color: #667eea;
            text-decoration: none;
            margin: 0 15px;
        }

        footer a:hover {
            text-decoration: underline;
        }

        /* Responsive */
        @media (max-width: 768px) {
            h1 {
                font-size: 2rem;
            }

            h2 {
                font-size: 1.5rem;
            }

            .features {
                grid-template-columns: 1fr;
            }

            .stats {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <!-- Header -->
    <header>
        <h1>Reinforcement Learning Navigation</h1>
        <p class="subtitle">Training Intelligent Agents with Deep Q-Learning</p>
    </header>

    <!-- Main Content -->
    <div class="container">
        <!-- About Section -->
        <section>
            <h2>About the Project</h2>
            <p>
                This project demonstrates a reinforcement learning application that uses Deep Q-Learning (DQN) 
                to train an agent to navigate complex environments. The agent learns optimal policies through 
                trial and error, maximizing cumulative rewards over time.
            </p>
            <p>
                Our approach combines experience replay, target networks, and epsilon-greedy exploration to 
                achieve stable and efficient learning. The trained agent exhibits intelligent behavior and can 
                generalize to unseen scenarios.
            </p>
        </section>

        <!-- Demo Video -->
        <section>
            <h2>Demo Video</h2>
            <div class="video-container">
                <!-- Replace VIDEO_ID with your YouTube video ID -->
                <iframe 
                    src="https://www.youtube.com/embed/VIDEO_ID" 
                    frameborder="0" 
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                    allowfullscreen>
                </iframe>
            </div>
            <p>
                Watch the trained agent navigate through a challenging environment, demonstrating learned 
                behaviors and optimal path planning.
            </p>
        </section>

        <!-- Key Features -->
        <section>
            <h2>Key Features</h2>
            <div class="features">
                <div class="feature">
                    <h3>Deep Q-Network</h3>
                    <p>Implements DQN with experience replay and target networks for stable learning</p>
                </div>
                <div class="feature">
                    <h3>Real-time Visualization</h3>
                    <p>Monitor agent performance with live metrics and reward tracking</p>
                </div>
                <div class="feature">
                    <h3>Optimized Training</h3>
                    <p>Efficient training pipeline with GPU acceleration support</p>
                </div>
            </div>
        </section>

        <!-- Results -->
        <section>
            <h2>Results</h2>
            <div class="stats">
                <div class="stat">
                    <div class="stat-value">250+</div>
                    <div class="stat-label">Average Reward</div>
                </div>
                <div class="stat">
                    <div class="stat-value">95%</div>
                    <div class="stat-label">Success Rate</div>
                </div>
                <div class="stat">
                    <div class="stat-value">1M+</div>
                    <div class="stat-label">Training Steps</div>
                </div>
            </div>
            <p>
                After 500,000 training steps, the agent achieved an average reward of 250+ and successfully 
                solved the environment with a 95% success rate. The model demonstrates robust performance 
                across different starting conditions.
            </p>
        </section>

        <!-- Technical Details -->
        <section>
            <h2>Technical Details</h2>
            <ul class="tech-list">
                <li><strong>Algorithm:</strong> Deep Q-Learning with Double DQN improvements</li>
                <li><strong>Framework:</strong> PyTorch / TensorFlow</li>
                <li><strong>Environment:</strong> OpenAI Gym</li>
                <li><strong>Training:</strong> 1M+ timesteps with epsilon-greedy exploration</li>
                <li><strong>Network:</strong> 3-layer CNN + 2 fully connected layers</li>
                <li><strong>Optimization:</strong> Adam optimizer with learning rate 0.0001</li>
            </ul>
        </section>
    </div>

    <!-- Footer -->
    <footer>
        <p>
            <a href="https://github.com/yourusername/your-repo">View on GitHub</a>
            <a href="mailto:your.email@example.com">Contact</a>
        </p>
        <p style="margin-top: 20px; color: #999;">&copy; 2026 Your Name. All rights reserved.</p>
    </footer>
</body>
</html>
